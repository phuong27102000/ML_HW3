Reading fashion MNIST data...
<class 'numpy.ndarray'>
Done reading
0.06952247300068848
0.024343490998944617
0.02165120800054865
0.02098140899943246
0.021892459999435232
0.021152041999812354
0.021816626000145334
0.02176735499961069
0.02263759199922788
0.021977648999381927
Epoch 10: train loss is 0.97764, validate loss is 1.01140
0.0697503660012444
0.029998304999026004
0.028566135000801296
0.033201084999745945
0.034766108999974676
0.027652188999127247
0.030582154000512674
0.0296550950006349
0.024376895000386867
0.02400175900038448
Epoch 20: train loss is 0.80225, validate loss is 0.84603
0.025130464000540087
0.02385357099956309
0.02333675000045332
0.0248080299988942
0.02285346399912669
0.023913529999845196
0.02194835899899772
0.022965377000218723
0.022836956999526592
0.022895841000718065
Epoch 30: train loss is 0.72267, validate loss is 0.77675
0.024430127999949036
0.02520692600046459
0.024148290998709854
0.024067461999948137
0.023075041999618406
0.022613289000219083
0.0248691319993668
0.024520648999896366
0.023645606999707525
0.022834720000901143
Epoch 40: train loss is 0.67269, validate loss is 0.73515
0.03588491799928306
0.02217802599989227
0.02230946599956951
0.02122204399893235
0.02280267899914179
0.022277119000136736
0.021605289999570232
0.021966693000649684
0.02241389899973001
0.021952527000394184
Epoch 50: train loss is 0.63678, validate loss is 0.70628
0.038911219000510755
0.02206977999958326
0.021840292998604127
0.022532219998538494
0.021996853000018746
0.022455927000919473
0.02111320699987118
0.02234499699989101
0.022704925999278203
0.021838709000803647
Epoch 60: train loss is 0.60899, validate loss is 0.68466
0.0429314869998052
0.022204118000445305
0.022555105000719777
0.021754781999334227
0.022007159001077525
0.022815754000475863
0.021526644999539712
0.02248747800149431
0.022508397998535656
0.022375873999408213
Epoch 70: train loss is 0.58647, validate loss is 0.66767
0.02708536600039224
0.022506318000523606
0.021643734000463155
0.022551901998667745
0.022083517000282882
0.021535735999350436
0.022993552000116324
0.022263668000960024
0.021080974000142305
0.02140461300041352
Epoch 80: train loss is 0.56762, validate loss is 0.65389
0.02526167599899054
0.022852178000903223
0.022437196001192206
0.02231181799834303
0.02280299799895147
0.02209510499960743
0.022817103999841493
0.021845442000994808
0.022342048001519288
0.021562655001616804
Epoch 90: train loss is 0.55146, validate loss is 0.64244
0.0377962460006529
0.011269811000602203
0.011822743001175695
0.011078661000283319
0.012013671999739017
0.01166576000105124
0.011760666999180103
0.011045809000279405
0.01045773499936331
0.011627169000348658
Epoch 100: train loss is 0.53736, validate loss is 0.63276
0.02883655500045279
0.013897255999836489
0.009900697001285153
0.009489193000263185
0.010800680000102147
0.01008646599984786
0.010466679999808548
0.010175101000641007
0.009620729000744177
0.00985269200100447
Epoch 110: train loss is 0.52487, validate loss is 0.62445
0.023591894998389762
0.014841931000773911
0.01159912900038762
0.012372872999549145
0.011523835999469156
0.01116762199853838
0.011665897000057157
0.011673263999909977
0.012148054000135744
0.011386940999727813
Epoch 120: train loss is 0.51367, validate loss is 0.61724
0.02617406699937419
0.0127779680005915
0.011687092001011479
0.011316570000417414
0.01153582799997821
0.01143568299994513
0.011243735001698951
0.011233609999180771
0.011804040999777499
0.010989583999617025
Epoch 130: train loss is 0.50353, validate loss is 0.61093
0.01617602799888118
0.011637544999757665
0.011345160999553627
0.011455391000708914
0.01157233300000371
0.011256357000092976
0.011481804000140983
0.011248680999415228
0.011151856999276788
0.011627489000602509
Epoch 140: train loss is 0.49427, validate loss is 0.60535
0.025563542998497724
0.013842831000147271
0.011374707999493694
0.011481329000162077
0.011604192000959301
0.011863182999150013
0.011344521999490098
0.011174463999850559
0.011255097999310237
0.011059299000407918
Epoch 150: train loss is 0.48577, validate loss is 0.60039
0.028422812998542213
0.013032179000219912
0.011385863999748835
0.011242935999689507
0.011712950999935856
0.011794414000178222
0.011481231000288972
0.01153568500012625
0.012127430998589261
0.011057282999900053
Epoch 160: train loss is 0.47789, validate loss is 0.59596
0.021811519998664153
0.01280350900015037
0.012655236998398323
0.01190308900004311
0.012011426000754
0.011899962999450509
0.011790646000008564
0.013172558001315338
0.011065878001318197
0.012179248000393272
Epoch 170: train loss is 0.47057, validate loss is 0.59197
0.03154627399999299
0.011293530000330065
0.01075058300011733
0.012395407000440173
0.011792283999966457
0.012148572999649332
0.01189340800010541
0.01133187900086341
0.011694429000272066
0.012083713998435996
Epoch 180: train loss is 0.46373, validate loss is 0.58837
0.02603993599950627
0.013555801000620704
0.011142642999402597
0.01130102800016175
0.010644771999068325
0.011576893999517779
0.011567319999812753
0.01129702499929408
0.012298481000470929
0.011062459001550451
Epoch 190: train loss is 0.45731, validate loss is 0.58511
0.02240506900125183
0.01182555499872251
0.011995413000477129
0.011884101999385166
0.01122175300042727
0.011429940001107752
0.012214985999889905
0.011640943999736919
0.012388323999402928
0.011344221000399557
Epoch 200: train loss is 0.45127, validate loss is 0.58214
0.03316873400035547
0.014495249999527005
0.011076793000029284
0.012127325000619749
0.011266121999142342
0.011490777000290109
0.011662472999887541
0.01122440099970845
0.01069064100011019
0.01163234200066654
Epoch 210: train loss is 0.44556, validate loss is 0.57943
0.03429409000091255
0.014472200000454905
0.012501793999035726
0.012742294000418042
0.01295353300156421
0.01245426400055294
0.012507878000178607
0.011858390000270447
0.012250394000147935
0.012665885000387789
Epoch 220: train loss is 0.44015, validate loss is 0.57694
0.028301438000198686
0.014062042000659858
0.011988016000032076
0.0116866200005461
0.01139784699989832
0.011830622001070878
0.011844125001516659
0.011722216999260127
0.012070093000147608
0.010997282999596791
Epoch 230: train loss is 0.43501, validate loss is 0.57466
0.025943925000319723
0.010827086000062991
0.011355754999385681
0.011998722000498674
0.010622237999996287
0.012021253998682369
0.011705246000929037
0.011007072000211338
0.011590666999836685
0.011114266000731732
Epoch 240: train loss is 0.43012, validate loss is 0.57256
0.027766183999119676
0.01306105399999069
0.010157643000638927
0.009976412000469281
0.00996378200034087
0.010318298000129289
0.009938364000845468
0.009436852998987888
0.009095606999835582
0.00972214400098892
Epoch 250: train loss is 0.42545, validate loss is 0.57062
0.010528057000556146
0.009982497998862527
0.009960442999727093
0.01015548299983493
0.010402877000160515
0.010101575999215129
0.010239561999696889
0.010162043998207082
0.011095480000221869
0.010835144999873592
Epoch 260: train loss is 0.42098, validate loss is 0.56883
0.03078865900170058
0.012608569999429164
0.009921703000145499
0.009997229999498813
0.009472740001001512
0.009947667000233196
0.009389930999532226
0.009607421001419425
0.010604646000501816
0.010050535000118543
Epoch 270: train loss is 0.41670, validate loss is 0.56717
0.027233901999352383
0.011450643998614396
0.009666011999797774
0.009990136999476817
0.009763852000105544
0.009248853999451967
0.009796620999622974
0.01019039899983909
0.009694942000351148
0.009840927999903215
Epoch 280: train loss is 0.41260, validate loss is 0.56562
0.011782348999986425
0.009703214000182925
0.009527725000225473
0.009286668999266112
0.009906596000291756
0.010407072000816697
0.00979665699924226
0.010105205999934697
0.009712843999295728
0.009529205000944785
Epoch 290: train loss is 0.40865, validate loss is 0.56419
0.012471162001020275
0.010500671000045259
0.00916672199855384
0.010451992999151116
0.010669268000128795
0.009660648000135552
0.01072048100104439
0.009963595000954228
0.00979360900055326
0.009091545000046608
Epoch 300: train loss is 0.40485, validate loss is 0.56285
0.024958166999567766
0.012391254000249319
0.009599656999853323
0.009752443000252242
0.010302658998625702
0.010828671000126633
0.00940439999976661
0.009803053999348776
0.010519769999518758
0.009053468000274734
Epoch 310: train loss is 0.40119, validate loss is 0.56159
0.027107539999633445
0.009915823999108397
0.01023188499857497
0.009842273999311146
0.009768709000127274
0.009835498998654657
0.009275213998989784
0.010441978000017116
0.00959684499866853
0.009299698998802342
Epoch 320: train loss is 0.39766, validate loss is 0.56042
0.031139361000896315
0.013109170999086928
0.009906923000016832
0.010235433999696397
0.010034969000116689
0.009639522000725265
0.00918285399893648
0.009274349999031983
0.010005934000218986
0.009288131999710458
Epoch 330: train loss is 0.39425, validate loss is 0.55932
0.027555726001082803
0.01324671500151453
0.010185466999246273
0.010146959999474348
0.009599965998859261
0.009884205001071678
0.010060463999252534
0.009367558001031284
0.009526443000140716
0.009606993000488728
Epoch 340: train loss is 0.39095, validate loss is 0.55829
0.030761259000428254
0.013949041000159923
0.010883551998631447
0.009684291000667145
0.010486082999705104
0.01015305900000385
0.009289862000514404
0.010421166000014637
0.010726401998908841
0.00965499800076941
Epoch 350: train loss is 0.38775, validate loss is 0.55733
0.025300066999989212
0.012256113999683294
0.009857087999989744
0.01028697000037937
0.01002748800055997
0.00995359999978973
0.010092870999869774
0.010327058000257239
0.009676783998656902
0.009899138000037055
Epoch 360: train loss is 0.38466, validate loss is 0.55642
0.02893934299936518
0.013393361999987974
0.010429316000227118
0.010187428000790533
0.011583075000089593
0.012419221999152796
0.012809649999326211
0.010167118998651858
0.01055921999977727
0.010806668000441277
Epoch 370: train loss is 0.38166, validate loss is 0.55556
0.026283160999810207
0.013007831999857444
0.010723588999098865
0.009682672998678754
0.009639197000069544
0.00962565900044865
0.009688452000773395
0.0097912040000665
0.009540108001601766
0.009685745000751922
Epoch 380: train loss is 0.37874, validate loss is 0.55475
0.030010734000825323
0.013431714000034845
0.010243153999908827
0.00952983199931623
0.009414029000254232
0.008780869000474922
0.00888176599983126
0.009240974999556784
0.009514110000964138
0.009892764001051546
Epoch 390: train loss is 0.37591, validate loss is 0.55399
0.02391851399988809
0.011204532000192557
0.009625940001569688
0.0095719149994693
0.009494524998444831
0.009775971999260946
0.010486330000276212
0.00959155400050804
0.009066160999282147
0.009866254000371555
Epoch 400: train loss is 0.37316, validate loss is 0.55327
0.011802261999037
0.010436274000312551
0.0095258150013251
0.008976092000011704
0.010819914999956382
0.01020032799897308
0.009430763000636944
0.00987786500081711
0.009820235000006505
0.00975115400069626
Epoch 410: train loss is 0.37048, validate loss is 0.55258
0.020085263000510167
0.009417801000381587
0.01010264999968058
0.010139062998860027
0.00951029899988498
0.00982253700021829
0.010483703999852878
0.009898182999677374
0.009709100000691251
0.009466437000810402
Epoch 420: train loss is 0.36787, validate loss is 0.55194
0.012933817000885028
0.010077151000587037
0.010426513999846065
0.009205550000842777
0.009500710000793333
0.009651160000430536
0.009966136000002734
0.010508393001146032
0.009362786000565393
0.009663156999522471
Epoch 430: train loss is 0.36534, validate loss is 0.55133
0.027841293000165024
0.013516818000425701
0.01011432999985118
0.009435639000002993
0.010576055999990785
0.009227869999449467
0.01002560799861385
0.009650305999457487
0.009690126998975757
0.009678381000412628
Epoch 440: train loss is 0.36286, validate loss is 0.55075
0.01050160700106062
0.009781660000953707
0.00970368399975996
0.010125426000740845
0.009230240000761114
0.010318267999537056
0.009736101999806124
0.009346412000013515
0.00980765100030112
0.009273247000237461
Epoch 450: train loss is 0.36045, validate loss is 0.55020
0.0195310969993443
0.009853624000243144
0.009579100000337348
0.010122814999704133
0.009733722999953898
0.00981008400049177
0.01029106399982993
0.009812891999899875
0.010284317999321502
0.009429369001736632
Epoch 460: train loss is 0.35809, validate loss is 0.54967
0.030175620000591152
0.012857424000685569
0.010051261999251437
0.00924912800110178
0.009958936998373247
0.009490933000051882
0.010021434000009322
0.009522062999167247
0.010043341000709916
0.00967349600068701
Epoch 470: train loss is 0.35579, validate loss is 0.54918
0.02671555199958675
0.013322905000677565
0.010130947999641648
0.009959361999790417
0.009857590999672539
0.009931972999766003
0.01083976299923961
0.009822021000218228
0.009263404999728664
0.009283244000471313
Epoch 480: train loss is 0.35354, validate loss is 0.54871
0.029484832000889583
0.00966365299973404
0.010523093998926925
0.010021899999628658
0.010318762000679271
0.009979922000638908
0.009439191000637948
0.009673652999481419
0.009608409000065876
0.009731411000757362
Epoch 490: train loss is 0.35135, validate loss is 0.54826
0.02702815199882025
0.013184817998990184
0.01044956599980651
0.010172121001232881
0.00956242499887594
0.009644869000112521
0.010220725000181119
0.010346372000640258
0.010218708999673254
0.009334907999800635
Epoch 500: train loss is 0.34920, validate loss is 0.54783
0.01939319799930672
0.009911717999784742
0.01007705200026976
0.010238492999633309
0.009802949000004446
0.009249693001038395
0.009887029998935759
0.010087018999911379
0.010338246000173967
0.00997615400046925
Epoch 510: train loss is 0.34710, validate loss is 0.54743
0.03215004300000146
0.01817960900007165
0.011016682999979821
0.010339222999391495
0.010039260001576622
0.010187122999923304
0.009707403998618247
0.009895746999973198
0.00998372100002598
0.009145321999312728
Epoch 520: train loss is 0.34504, validate loss is 0.54704
0.02819141799955105
0.015392344999781926
0.010752000998763833
0.009316927000327269
0.009693726999103092
0.010404274000393343
0.00938181700075802
0.01000858900079038
0.009799268000278971
0.010567572999207187
Epoch 530: train loss is 0.34303, validate loss is 0.54668
0.030577845000152593
0.013515271999494871
0.01057256600142864
0.009428795998246642
0.009837622999839368
0.009823943000810686
0.010295114998370991
0.009436283999093575
0.009763060999830486
0.009673202001067693
Epoch 540: train loss is 0.34106, validate loss is 0.54633
0.024080154000330367
0.012513865998698748
0.010080260999529855
0.010492892999536707
0.009342864001155249
0.010092296999573591
0.010519192999709048
0.009085450999918976
0.00971713900071336
0.009467214998949203
Epoch 550: train loss is 0.33912, validate loss is 0.54599
0.010526946000027237
0.009724901001391117
0.009909525000693975
0.009471577001022524
0.009790510999664548
0.009749233000547974
0.013187475999075104
0.009488854000665015
0.00949764500001038
0.01010079899970151
Epoch 560: train loss is 0.33723, validate loss is 0.54568
0.01931323099961446
0.009498253999481676
0.010064780999528011
0.009628726000300958
0.010234199999104021
0.00984395100022084
0.009947947000910062
0.00999290999970981
0.009842503999607288
0.010062934999950812
Epoch 570: train loss is 0.33537, validate loss is 0.54538
0.02978476000134833
0.015213851000225986
0.011801972999819554
0.009530994000670034
0.010435328000312438
0.011146943001222098
0.010145422998903086
0.010655484000380966
0.009206508000715985
0.009320142000433407
Epoch 580: train loss is 0.33355, validate loss is 0.54509
0.025039246000233106
0.012832042000809452
0.010366152000642614
0.010076063001179136
0.009674909999375814
0.009036187000674545
0.009673521999502555
0.009586967000359436
0.010361106998971081
0.009162611999272485
Epoch 590: train loss is 0.33176, validate loss is 0.54482
0.026589387000058196
0.01225969999904919
0.00953083400054311
0.009777846998986206
0.00973570399946766
0.009215673000653624
0.009560724998664227
0.009206487000483321
0.01004584800102748
0.00995276499997999
Epoch 600: train loss is 0.33001, validate loss is 0.54456
0.03143621799972607
0.012386938000418013
0.009853409999777796
0.009226494999893475
0.009554793999996036
0.009326744000645704
0.010096129999510595
0.01041574699956982
0.009629108000808628
0.010599420998914866
Epoch 610: train loss is 0.32828, validate loss is 0.54432
0.027236673999141203
0.012758535000102711
0.010781573000713252
0.010148883000510978
0.010917662999418098
0.010282445000484586
0.009047335999639472
0.011482870000691037
0.009147298000243609
0.009404336000443436
Epoch 620: train loss is 0.32659, validate loss is 0.54408
0.021350094999434077
0.015957749001245247
0.010081231001095148
0.009254778000467923
0.009554207999826758
0.009434495999812498
0.010353398000006564
0.01010654799938493
0.01027282799987006
0.010438560999318724
Epoch 630: train loss is 0.32493, validate loss is 0.54386
0.021398460999989766
0.009386037998410757
0.009677822999947239
0.009617382998840185
0.00925358399945253
0.009877173999484512
0.01036775800093892
0.009654666000642464
0.00983464700038894
0.010045491999335354
Epoch 640: train loss is 0.32330, validate loss is 0.54365
0.02574708399879455
0.01615787800074031
0.011811615000624442
0.010114306998730171
0.009964217999367975
0.009629749998566695
0.01105174199983594
0.009798524000871112
0.009902063999106758
0.009075922000192804
Epoch 650: train loss is 0.32169, validate loss is 0.54345
0.032550738000281854
0.014160894001179258
0.011518712999532
0.011544181999852299
0.01137865700002294
0.009311867999713286
0.010026893000031123
0.010172046999286977
0.010636421999151935
0.01020243699895218
Epoch 660: train loss is 0.32011, validate loss is 0.54326
0.010864451000088593
0.01000585000110732
0.010336633000406437
0.010204157999396557
0.009834832000706228
0.010092524000356207
0.0096197189996019
0.010016784000981716
0.010266762999890489
0.009655305000705994
Epoch 670: train loss is 0.31856, validate loss is 0.54308
0.025328097999590682
0.012485433000620105
0.010581630000160658
0.012225918000694946
0.011913410999113694
0.010517843000343419
0.0111134779999702
0.009832486000959761
0.010463159000209998
0.009792246000870364
Epoch 680: train loss is 0.31703, validate loss is 0.54291
0.028977256999496603
0.014001741999891237
0.009995991000323556
0.010556809000263456
0.009244322000085958
0.009924296000463073
0.009322601999883773
0.009510791000138852
0.009739938001075643
0.009653008999521262
Epoch 690: train loss is 0.31552, validate loss is 0.54275
0.025350509999043425
0.012294508000195492
0.009806070000195177
0.009572934000971145
0.009901548999550869
0.009740209001392941
0.009645148000345216
0.010034810999059118
0.00965234500108636
0.008947760001319693
Epoch 700: train loss is 0.31404, validate loss is 0.54259
0.011779686001318623
0.009783773999515688
0.009385686998939491
0.009328075999292196
0.00990748000003805
0.009205124999425607
0.009420075999514665
0.009475552998992498
0.010220969999863883
0.009323960999608971
Epoch 710: train loss is 0.31259, validate loss is 0.54245
0.030168544000844122
0.012787009000021499
0.00956079799834697
0.009813388000111445
0.009604517999832751
0.0102539239996986
0.010553502999755437
0.009744761000547442
0.009103582999159698
0.009710899999845424
Epoch 720: train loss is 0.31115, validate loss is 0.54232
0.033155056000396144
0.01338812100038922
0.01032449099875521
0.009404528000231949
0.009906826000587898
0.009831979999944451
0.009368817998620216
0.010323055001208559
0.008957023001130437
0.009216444999765372
Epoch 730: train loss is 0.30974, validate loss is 0.54219
0.024170955999579746
0.012081943999874056
0.009225822001099004
0.0091323549986555
0.010684975999538437
0.010639513000569423
0.009352340999612352
0.009992924000471248
0.00987324599918793
0.009775265998541727
Epoch 740: train loss is 0.30835, validate loss is 0.54207
0.026387207000880153
0.012968790000741137
0.010007906001192168
0.010652300999936415
0.00969787699978042
0.010071615999549977
0.009388824999405188
0.009906761000820552
0.010109933999046916
0.010532849000810529
Epoch 750: train loss is 0.30698, validate loss is 0.54196
0.013535685000533704
0.010132089999387972
0.010036092999143875
0.009853854000539286
0.00987014000020281
0.010269029000482988
0.009361824000734487
0.00941365600010613
0.010043096999652334
0.010074204999909853
Epoch 760: train loss is 0.30562, validate loss is 0.54185
0.026140136000321945
0.009710475000247243
0.010154063000300084
0.009844719999819063
0.008977750001577078
0.01029613100035931
0.009172537000267766
0.01007495299927541
0.009186830000544433
0.009815747000175179
Epoch 770: train loss is 0.30429, validate loss is 0.54176
0.030946750001021428
0.012459034000130487
0.010359195001001353
0.010088071001518983
0.009044999000252574
0.009503887999017024
0.009284888999900431
0.009270177000871627
0.010248737000438268
0.010276850998707232
Epoch 780: train loss is 0.30298, validate loss is 0.54167
0.011613044998739497
0.010303345001375419
0.009269756999856327
0.010478451000381028
0.010020028999861097
0.010754576998806442
0.009981592000258388
0.00934776900066936
0.009761666000486002
0.010138295001524966
Epoch 790: train loss is 0.30168, validate loss is 0.54158
0.03155724200041732
0.012731516999338055
0.010556697001447901
0.010157266000533127
0.00978664300055243
0.010123670999746537
0.00952558099925227
0.010813678998601972
0.009253297999748611
0.009095542000068235
Epoch 800: train loss is 0.30040, validate loss is 0.54150
0.031018207999295555
0.012553378999655251
0.010195272001510602
0.009764254000401706
0.009250540999346413
0.010256379000566085
0.010191485000177636
0.009968629001377849
0.009055559001353686
0.009209648000251036
Epoch 810: train loss is 0.29914, validate loss is 0.54143
0.021238889999949606
0.011609956000029342
0.009107799000048544
0.009324482000010903
0.010403649999716436
0.010728262001066469
0.009190008999212296
0.009350750000521657
0.010558874999333057
0.009714669000459253
Epoch 820: train loss is 0.29790, validate loss is 0.54137
0.01951446999919426
0.009855967999101267
0.010380095000073197
0.010481762001290917
0.00960160700014967
0.0096223620003002
0.009294753999711247
0.010040516001026845
0.009565132000716403
0.009736345000419533
Epoch 830: train loss is 0.29667, validate loss is 0.54131
0.024709434999749647
0.012233961000674753
0.010457856000357424
0.009192309000354726
0.010829849999936414
0.009483194999120315
0.009747302001414937
0.009711771999718621
0.009619647998988512
0.009429017000002204
Epoch 840: train loss is 0.29546, validate loss is 0.54125
0.02733290499963914
0.012447912000425276
0.009605223000107799
0.010250506000375026
0.010659726000085357
0.010392465999757405
0.009468150999964564
0.009287089000281412
0.00939855000069656
0.00972890999946685
Epoch 850: train loss is 0.29427, validate loss is 0.54121
0.013407131000349182
0.010114669999893522
0.010083520999614848
0.009488040999713121
0.01015129799998249
0.011701913999786484
0.009342246999949566
0.00971731099889439
0.009556995999446372
0.010225932999674114
Epoch 860: train loss is 0.29309, validate loss is 0.54116
0.032062181999208406
0.013921906000177842
0.010231992000626633
0.009736107000207994
0.010117108999111224
0.00984917499954463
0.010038500999144162
0.009633592999307439
0.009128339001108543
0.009429241999896476
Epoch 870: train loss is 0.29192, validate loss is 0.54113
0.02713076399959391
0.013153874999261461
0.00953226599995105
0.010074718000396388
0.010237681999569759
0.009887203001198941
0.010700884000470978
0.009842014000241761
0.00965112800076895
0.009827034000409185
Epoch 880: train loss is 0.29077, validate loss is 0.54109
0.012793920999683905
0.010240929999781656
0.009921028000462684
0.01007221399959235
0.010395276000053855
0.009988111998609384
0.010009540001192363
0.01010732599934272
0.009752167999977246
0.00979392400040524
Epoch 890: train loss is 0.28963, validate loss is 0.54107
0.028398545999152702
0.012040384999636444
0.010229516999970656
0.009953201000826084
0.009972387999368948
0.010229583000182174
0.009955830000762944
0.01077770300071279
0.009697642000901396
0.01058580099925166
Epoch 900: train loss is 0.28851, validate loss is 0.54104
0.02462236999963352
0.0096593540001777
0.010338088999560568
0.009049045000210754
0.009904475000439561
0.009753598998941015
0.00948402299945883
0.009668849999798113
0.009139777999735088
0.009335936998468242
Epoch 910: train loss is 0.28740, validate loss is 0.54103
0.028580055999555043
0.012000647000604658
0.00961146000008739
0.010282512999765459
0.010383148000983056
0.010095776999150985
0.00993064999966009
0.010010527999838814
0.009982292000131565
0.00944163500025752
Epoch 920: train loss is 0.28630, validate loss is 0.54101
0.025550042000759277
0.012414586999511812
0.009657057000367786
0.009490346999882604
0.009930675001669442
0.009357454000564758
0.009786734999579494
0.01006129300003522
0.00904687700131035
0.009592925000106334
Epoch 930: train loss is 0.28522, validate loss is 0.54100
0.026686405999498675
0.013225467000665958
0.009820892000789172
0.00919800799965742
0.009642385999541148
0.009849718000623398
0.010441995000292081
0.009022942000228795
0.009967113999664434
0.009750159999384778
Epoch 940: train loss is 0.28415, validate loss is 0.54100
0.02599727599954349
0.012851659001171356
Training iteration stop at iteration 941
Confusion matrix:
[[0.93 0.   0.02 0.04 0.   0.   0.02 0.   0.   0.  ]
 [0.02 0.95 0.   0.03 0.   0.   0.   0.   0.   0.  ]
 [0.02 0.   0.61 0.04 0.22 0.   0.11 0.   0.   0.  ]
 [0.07 0.05 0.   0.8  0.03 0.   0.05 0.   0.   0.  ]
 [0.   0.   0.09 0.05 0.74 0.   0.12 0.   0.   0.  ]
 [0.   0.   0.   0.   0.   0.92 0.   0.08 0.   0.  ]
 [0.23 0.   0.09 0.02 0.19 0.   0.45 0.   0.02 0.  ]
 [0.   0.   0.   0.   0.   0.06 0.   0.84 0.   0.1 ]
 [0.   0.   0.   0.02 0.02 0.04 0.   0.   0.93 0.  ]
 [0.   0.   0.   0.   0.   0.02 0.   0.   0.   0.98]]
Diagonal values:
[0.93 0.95 0.61 0.8  0.74 0.92 0.45 0.84 0.93 0.98]
