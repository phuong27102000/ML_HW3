Reading fashion MNIST data...
<class 'numpy.ndarray'>
Done reading
0.0069805659986741375
0.005939701000897912
0.005960336999123683
0.005797639998490922
0.006176357001095312
0.005800699000246823
0.005898101000639144
0.005691799000487663
0.006003047001286177
0.006213876000401797
Epoch 10: train loss is 0.94917, validate loss is 0.98509
0.052661256999272155
0.03213304299788433
0.057932394000090426
0.045019140001386404
0.01836487299806322
0.02142066000305931
0.025182121000398183
0.018264659000124084
0.023025824997603195
0.013135309000062989
Epoch 20: train loss is 0.78084, validate loss is 0.82731
0.014641991998360027
0.02051467999990564
0.012075825001375051
0.011597016000450822
0.011023758997907862
0.011798104998888448
0.011239601000852417
0.011862695999298012
0.011538106999068987
0.011760801997297676
Epoch 30: train loss is 0.70409, validate loss is 0.76113
0.035083365997707006
0.026868314998864662
0.017894249001983553
0.022408256998460274
0.02009173899932648
0.03865020900047966
0.025178968000545865
0.02319570499821566
0.020208512996759964
0.020957617998647038
Epoch 40: train loss is 0.65565, validate loss is 0.72134
0.016252674999122974
0.0198709050018806
0.022016654002072755
0.016506699001183733
0.015948487001878675
0.01572970200140844
0.010794681002153084
0.018050986000162084
0.010648241997841978
0.009850812999502523
Epoch 50: train loss is 0.62071, validate loss is 0.69370
0.008325803002662724
0.0068625880012405105
0.007052769000438275
0.0067325290001463145
0.007017329000518657
0.0071186729983310215
0.0074922980020346586
0.007592023001052439
0.005888522999157431
0.0295916169998236
Epoch 60: train loss is 0.59363, validate loss is 0.67302
0.028700126000330783
0.009565857999405125
0.007831337999959942
0.006877949999761768
0.01017425800091587
0.0063262589974328876
0.005851478999829851
0.006335425001452677
0.019109929002297577
0.007895712999015814
Epoch 70: train loss is 0.57165, validate loss is 0.65680
0.03660765600216109
0.015210711000690935
0.013210977998824092
0.008989883001049748
0.00883581900052377
0.009377652997500263
0.009156833999441005
0.009174115999485366
0.009290740999858826
0.009162148999166675
Epoch 80: train loss is 0.55324, validate loss is 0.64368
0.030369574000360444
0.025151805002678884
0.014455912001722027
0.010642395998729626
0.00970419899749686
0.008465585000521969
0.008565534997615032
0.008588869997765869
0.008361435000551865
0.008619775999250123
Epoch 90: train loss is 0.53744, validate loss is 0.63281
0.02041967399782152
0.03174160500202561
0.02725075299895252
0.009771524997631786
0.008444852999673458
0.008405257998674642
0.008630158001324162
0.011730786001862725
0.020684957002231386
0.009721227001136867
Epoch 100: train loss is 0.52363, validate loss is 0.62365
0.04085096000198973
0.014366311999765458
0.01010359000065364
0.007220315001177369
0.006320944001345197
0.005995322000671877
0.005929007002123399
0.005811336999613559
0.005869507000170415
0.008850038000673521
Epoch 110: train loss is 0.51140, validate loss is 0.61581
0.04761981000046944
0.012093733999790857
0.008409015998040559
0.00931653599764104
0.009081303000129992
0.008845053002005443
0.009297477001382504
0.008337161998497322
0.008995536001748405
0.02052512999944156
Epoch 120: train loss is 0.50041, validate loss is 0.60903
0.015573205000691814
0.013689303999854019
0.015469992998987436
0.009769407999556279
0.007674460000998806
0.006794240998715395
0.008040830001846189
0.008391107003262732
0.008374471999559319
0.0071457439989899285
Epoch 130: train loss is 0.49046, validate loss is 0.60311
0.046790745996986516
0.020599555999069707
0.0110652969997318
0.006609998999920208
0.0062261590028356295
0.00619097100207
0.007776504000503337
0.006186194998008432
0.006298894000792643
0.005838835000758991
Epoch 140: train loss is 0.48137, validate loss is 0.59790
0.03978803199788672
0.016336855998815736
0.021646169996529352
0.03537796299860929
0.03302124900073977
0.017167382000479847
0.01685087000078056
0.0182578249987273
0.011174319999554427
0.011059836000640644
Epoch 150: train loss is 0.47300, validate loss is 0.59328
0.008603237001807429
0.00873393199799466
0.00822017400059849
0.008403072999499273
0.008301775997097138
0.008030851997318678
0.0062324140017153695
0.011270570001215674
0.005909665000217501
0.026852385999518447
Epoch 160: train loss is 0.46526, validate loss is 0.58916
0.037806109998200554
0.012512075998529326
0.00836923400129308
0.00823098499677144
0.006459567997808335
0.0061624090012628585
0.005893691999517614
0.006240926999453222
0.010587788998236647
0.011189930999535136
Epoch 170: train loss is 0.45805, validate loss is 0.58548
0.04575432599813212
0.015764447001856752
0.010069643998576794
0.00928315599958296
0.012601046997588128
0.011780486998759443
0.01047886699961964
0.009581238002283499
0.00969337299829931
0.009192683999572182
Epoch 180: train loss is 0.45131, validate loss is 0.58216
0.047616560997994384
0.01959551500112866
0.0123634330011555
0.009964051001588814
0.009592395999789005
0.009215606001816923
0.009259070000553038
0.009187056999508059
0.009396642999490723
0.009195017999445554
Epoch 190: train loss is 0.44498, validate loss is 0.57916
0.05407347400250728
0.013463994000630919
0.008211429001676152
0.0074303770015831105
0.0062425229989457875
0.006162039000628283
0.006323886998870876
0.005851120997249382
0.005869140997674549
0.006992933998844819
Epoch 200: train loss is 0.43902, validate loss is 0.57644
0.03622440399703919
0.03177521900215652
0.021608914001262747
0.009400130998983514
0.015395962000184227
0.0075463809989742
0.008167444000719115
0.006407408000086434
0.005799677001050441
0.007024079997790977
Epoch 210: train loss is 0.43339, validate loss is 0.57396
0.04872615199928987
0.017584870001883246
0.012349919001280796
0.00976701299805427
0.00911095600167755
0.006051098000170896
0.005940620001638308
0.0059118200006196275
0.005888427000172669
0.0061291669990168884
Epoch 220: train loss is 0.42805, validate loss is 0.57170
0.030207131003407994
0.021205820001341635
0.014782218000618741
0.009280571997805964
0.006462640001700493
0.005830809997860342
0.005799893999210326
0.008302042999275727
0.009020483001222601
0.00940210000044317
Epoch 230: train loss is 0.42297, validate loss is 0.56962
0.04259998300040024
0.02039203900130815
0.010270956001477316
0.007688196998060448
0.010941193999315146
0.009486978000495583
0.009511485000984976
0.009173884998745052
0.009326511000836035
0.00943493600061629
Epoch 240: train loss is 0.41814, validate loss is 0.56772
0.04316539999854285
0.017308348000369733
0.008834691998345079
0.00789134600199759
0.006677035999018699
0.006067972000892041
0.005848322998645017
0.005786665999039542
0.00627894400167861
0.005870975001016632
Epoch 250: train loss is 0.41352, validate loss is 0.56597
0.036383639999257866
0.01583483699869248
0.010457681000843877
0.04456665800171322
0.015755488002469065
0.008832094001263613
0.0093176720001793
0.009173909002129221
0.017829481002991088
0.009498145001998637
Epoch 260: train loss is 0.40911, validate loss is 0.56435
0.013874214000679785
0.009224354002071777
0.010174474999075755
0.011439593003160553
0.020368351997603895
0.02440962699984084
0.008447407999483403
0.0068601559978560545
0.0063899339984345715
0.005921650998061523
Epoch 270: train loss is 0.40488, validate loss is 0.56286
0.029699033999349922
0.019190372000593925
0.009589995999704115
0.007834178999473806
0.010261929000989767
0.009621107001294149
0.009223865999956615
0.009146127998974407
0.009455003000766737
0.009120611000980716
Epoch 280: train loss is 0.40082, validate loss is 0.56147
0.0067331799982639495
0.006322780998743838
0.006854125997051597
0.005784534998383606
0.00691910400200868
0.005775580000772607
0.006206311001733411
0.006854784998722607
0.006555306001246208
0.006618272000196157
Epoch 290: train loss is 0.39692, validate loss is 0.56018
0.02309007399890106
0.013909425000747433
0.010710455000662478
0.009985180000512628
0.00930625399996643
0.009767186998942634
0.009698829999251757
0.00969654599975911
0.009672434000094654
0.009635346999857575
Epoch 300: train loss is 0.39316, validate loss is 0.55898
0.011860561000503367
0.008745543000259204
0.007518324000557186
0.006747137998900143
0.007157310999900801
0.006981265996728325
0.010305182997399243
0.009426261000044178
0.009367800998006715
0.008918243998778053
Epoch 310: train loss is 0.38954, validate loss is 0.55787
0.03148678900106461
0.011920597000425914
0.00930166900070617
0.00806102699789335
0.008209124000131851
0.007025245999102481
0.007434821000060765
0.006943076001334703
0.006921435997355729
0.007315964998269919
Epoch 320: train loss is 0.38604, validate loss is 0.55682
0.02214757600086159
0.014247344999603229
0.0074363250023452565
0.00638157399953343
0.005957200002740137
0.005928776998189278
0.006105092998041073
0.006108812998718349
0.013044133000221336
0.006460083001002204
Epoch 330: train loss is 0.38267, validate loss is 0.55585
0.013552856002206681
0.008974063999630744
0.0074243939998268615
0.006902078999701189
0.00609710500066285
0.006087773999752244
0.005839377001393586
0.006234333002794301
0.005983120998280356
0.0057697990014276
Epoch 340: train loss is 0.37940, validate loss is 0.55493
0.008421262002229923
0.006014304999553133
0.00800908200108097
0.007397949000733206
0.0072820179993868805
0.0072905999986687675
0.00770879600167973
0.007679401998757385
0.00786745600271388
0.008296561001770897
Epoch 350: train loss is 0.37624, validate loss is 0.55408
0.01159263500085217
0.010167691001697676
0.01053336000040872
0.010103468997840537
0.009236062000127276
0.009585742001945619
0.011045142000511987
0.009199520001857309
0.009309278000728227
0.01089542499903473
Epoch 360: train loss is 0.37318, validate loss is 0.55327
0.03455792000022484
0.010186799998336937
0.007697503999224864
0.009057654002390336
0.006041385997377802
0.007898182000644738
0.020949839003151283
0.008712787999684224
0.010038178999820957
0.008617778999905568
Epoch 370: train loss is 0.37021, validate loss is 0.55252
0.01126171199939563
0.04299603099934757
0.012122111998905893
0.00852816999758943
0.006193241999426391
0.005742949000705266
0.006087099001888419
0.0057362369989277795
0.006180718002724461
0.006006890998833114
Epoch 380: train loss is 0.36732, validate loss is 0.55181
0.02589297099984833
0.02036299699830124
0.011041138001019135
0.008215338999434607
0.007072202999552246
0.006703331000608159
0.005789938000816619
0.006012871002894826
0.0057549510020180605
0.006295287999819266
Epoch 390: train loss is 0.36452, validate loss is 0.55114
0.04061151399946539
0.03540484400218702
0.01152902900139452
0.009153793998848414
0.008508290000463603
0.00864588799959165
0.009468912998272572
0.008437747001153184
0.008405971999309259
0.008462251000310061
Epoch 400: train loss is 0.36180, validate loss is 0.55051
0.0309303469985025
0.02087999099967419
0.015221008001390146
0.011328152999340091
0.009498170998995192
0.009793825000087963
0.009353009998449124
0.009703005001938436
0.009398927999427542
0.007569334000436356
Epoch 410: train loss is 0.35915, validate loss is 0.54991
0.030397414000617573
0.02979879999838886
0.015066870000737254
0.011156311000377173
0.009675469998910557
0.008425783998973202
0.00848363100158167
0.009167296000669012
0.008410796002863208
0.009181718000036199
Epoch 420: train loss is 0.35657, validate loss is 0.54935
0.04251707200091914
0.019905003002349986
0.008928231000027154
0.007093684002029477
0.00704510400100844
0.009074487999896519
0.010374754001531983
0.00923411700205179
0.009667905000242172
0.009227130001818296
Epoch 430: train loss is 0.35405, validate loss is 0.54882
0.05589115399925504
0.01279643800080521
0.012538388997199945
0.010382950997154694
0.009360100000776583
0.0067237969997222535
0.006798254999011988
0.006985025996982586
0.007441116998961661
0.007421163001708919
Epoch 440: train loss is 0.35160, validate loss is 0.54831
0.009608164000383113
0.0060997649998171255
0.006091571998695144
0.006792121999751544
0.005996908999804873
0.005858537999301916
0.006557042001077207
0.006226647001312813
0.00614970799870207
0.006154399998195004
Epoch 450: train loss is 0.34921, validate loss is 0.54784
0.02226117999816779
0.011592910999752348
0.008896921000996372
0.00935873400158016
0.006927456000994425
0.006990262998442631
0.00723165700037498
0.006887993000418646
0.006879328997456469
0.006953511001484003
Epoch 460: train loss is 0.34688, validate loss is 0.54739
0.007158389998949133
0.0071610739978495985
0.005982474998745602
0.006047138998837909
0.006673675001366064
0.006402254999557044
0.006027999999787426
0.006438560998503817
0.005952292998699704
0.010112423999089515
Epoch 470: train loss is 0.34460, validate loss is 0.54697
0.024356850000913255
0.013906239000789355
0.010861866001505405
0.009256158999050967
0.00937539000005927
0.009287426000810228
0.010864017000130843
0.008844899999530753
0.008370956998987822
0.008540070997696603
Epoch 480: train loss is 0.34238, validate loss is 0.54656
0.014620464000472566
0.013752378999924986
0.007437726999341976
0.006403682000382105
0.006295560997386929
0.006131572998128831
0.005813712003146065
0.008157566000591032
0.009232375003193738
0.0092346319979697
Epoch 490: train loss is 0.34021, validate loss is 0.54618
0.00684556400301517
0.0062085099998512305
0.005865244998858543
0.005824595002195565
0.0058432650002941955
0.005910243002290372
0.007973767998919357
0.0096476740000071
0.00943864400323946
0.010089127001265297
Epoch 500: train loss is 0.33808, validate loss is 0.54582
0.0070688349987904076
0.005871879999176599
0.00579335500151501
0.008082403997832444
0.008352720000402769
0.008351298001798568
0.008583830000134185
0.008319520999066299
0.008457849999103928
0.008686179000505945
Epoch 510: train loss is 0.33600, validate loss is 0.54548
0.015026844001113204
0.011025928000890417
0.009688431000540731
0.010126258999662241
0.009911133001878625
0.010359953997976845
0.010564041996985907
0.010382469001342542
0.010483900001418078
0.009508142997219693
Epoch 520: train loss is 0.33396, validate loss is 0.54516
0.019171334999555256
0.01082444200073951
0.009203639001498232
0.007740735996776493
0.007185943999502342
0.0069873860011284705
0.00769178599875886
0.008038062002015067
0.010265085002174601
0.01025419200232136
Epoch 530: train loss is 0.33197, validate loss is 0.54486
0.0211432700016303
0.012092692999431165
0.013313319999724627
0.010691387000406394
0.009141537000687094
0.008760839999013115
0.009240868999768281
0.008995526997750858
0.010806395999679808
0.008715460000530584
Epoch 540: train loss is 0.33002, validate loss is 0.54457
0.008260973998403642
0.0077786980000382755
0.006727829000737984
0.006770754000172019
0.00726553300046362
0.016341834001650568
0.010109232000104384
0.01025202999881003
0.010217554998234846
0.010553140000411076
Epoch 550: train loss is 0.32811, validate loss is 0.54429
0.046876728996721795
0.012563940999825718
0.01057815300009679
0.009301475001848303
0.011164453000674257
0.009612519999791402
0.009675212000729516
0.010111774998222245
0.010334295999200549
0.010038185002485989
Epoch 560: train loss is 0.32623, validate loss is 0.54404
0.043093511998449685
0.019891521998943062
0.01102470299883862
0.028839744998549577
0.026486556002055295
0.032084835998830386
0.036032143001648365
0.025345573001686716
0.014727244000823703
0.026914545000181533
Epoch 570: train loss is 0.32439, validate loss is 0.54379
0.014050658002815908
0.01786649199857493
0.031106187001569197
0.013471336002112366
0.01877080100166495
0.013019745001656702
0.015980067000782583
0.015557953000097768
0.017121297998528462
0.009510353000223404
Epoch 580: train loss is 0.32259, validate loss is 0.54356
0.026534728000115138
0.02452494500175817
0.00968183200166095
0.010605889001453761
0.009658621002017753
0.009652319000451826
0.011122679003165103
0.009243717999197543
0.010082770000735763
0.009947400998498779
Epoch 590: train loss is 0.32082, validate loss is 0.54335
0.043800670999189606
0.015531730998191051
0.011133936000987887
0.008786733000306413
0.008561178998206742
0.0079885520026437
0.006055354999261908
0.006216598001628881
0.0061581360023410525
0.008871582998835947
Epoch 600: train loss is 0.31908, validate loss is 0.54314
0.04268850799780921
0.0214623030005896
0.013376625000091735
0.007632991000718903
0.006034564001311082
0.006037291001121048
0.005842049999046139
0.006369114002154674
0.005867010000656592
0.006003709000651725
Epoch 610: train loss is 0.31738, validate loss is 0.54295
0.018911155002570013
0.029885728003137046
0.024838680001266766
0.009423297000466846
0.008039310003368882
0.016766321001341566
0.047111888001381885
0.025418356999580283
0.008998270001029596
0.009432520000700606
Epoch 620: train loss is 0.31570, validate loss is 0.54277
0.03128690599987749
0.020436556998902233
0.010971743999107275
0.008547249999537598
0.0069679410007665865
0.00679414299884229
0.005942227999184979
0.0058949310005118605
0.006015072998707183
0.008350412997970125
Epoch 630: train loss is 0.31405, validate loss is 0.54260
0.012256166999577545
0.012894500003312714
0.013611387999844737
0.012192171001515817
0.008865476000210037
0.00809624900284689
0.0066932910012837965
0.006084316999476869
0.005995835999783594
0.00583806200302206
Epoch 640: train loss is 0.31244, validate loss is 0.54244
0.026099603997863596
0.03358977099924232
0.016639113000564976
0.007603821999509819
0.006902088000060758
0.008328432999405777
0.009383663000335218
0.009229548999428516
0.009533538999676239
0.009453008999116719
Epoch 650: train loss is 0.31085, validate loss is 0.54229
0.027974139997240854
0.03332841399969766
0.010369324998464435
0.008403735002502799
0.011456303000159096
0.009399888000189094
0.00952452599813114
0.009403482999914559
0.009199539999826811
0.009863200000836514
Epoch 660: train loss is 0.30928, validate loss is 0.54215
0.03612777699891012
0.07302992499899119
0.00968069599912269
0.0069130779993429314
0.006054700999811757
0.006192459997691913
0.009042182999110082
0.005972609000309603
0.011927015999390278
0.00615766199916834
Epoch 670: train loss is 0.30774, validate loss is 0.54202
0.009192637000523973
0.008928898001613561
0.009520528998109512
0.009853323001152603
0.008694042000570334
0.01572330300041358
0.006206066998856841
0.006081324998376658
0.006541216000186978
0.0063696830002299976
Epoch 680: train loss is 0.30623, validate loss is 0.54190
0.024497225000231992
0.026527013000304578
0.014234727997973096
0.008422977000009269
0.007403930001601111
0.0068995039982837625
0.006176281000080053
0.005863767997652758
0.0059810309976455756
0.006291751000389922
Epoch 690: train loss is 0.30474, validate loss is 0.54179
0.030588311001338298
0.008778695002547465
0.008436023999820463
0.010093107001011958
0.00989569100056542
0.008674815002450487
0.009062749002623605
0.009330108998256037
0.008734817998629296
0.008983272997284075
Epoch 700: train loss is 0.30328, validate loss is 0.54169
0.023822412000299664
0.010102031999849714
0.008562328002881259
0.00697035700068227
0.006520119000924751
0.0060124420015199576
0.008321007997437846
0.009891552002954995
0.009516742000414524
0.00983310499941581
Epoch 710: train loss is 0.30183, validate loss is 0.54159
0.0357906470017042
0.014609947997087147
0.009149549001449486
0.00844427199990605
0.006649640999967232
0.006304681999608874
0.005929006001679227
0.00746070300010615
0.008596616000431823
0.008775268001045333
Epoch 720: train loss is 0.30041, validate loss is 0.54151
0.007202652999694692
0.0063392570009455085
0.006515197001135675
0.006475404003140284
0.006337377999443561
0.005821424998430302
0.006194102003064472
0.0059018379979534075
0.005917495996982325
0.00606702200093423
Epoch 730: train loss is 0.29901, validate loss is 0.54143
0.031465087999094976
0.015357136999227805
0.010188563999690814
0.00884944100107532
0.007550135000201408
0.007126259002689039
0.007177998999395641
0.007417482000164455
0.00774906100195949
0.0072749580031086225
Epoch 740: train loss is 0.29763, validate loss is 0.54136
0.026997900000424124
0.02585069699853193
0.015008120000857161
0.011590157002501655
0.00959669199801283
0.009587475000444101
0.02609136200044304
0.013990637999086175
0.02299588800087804
0.009592902002623305
Epoch 750: train loss is 0.29628, validate loss is 0.54129
0.03551193499879446
0.01991657100006705
0.009583850998751586
0.01600696499735932
0.006235566001123516
0.0060114170009910595
0.006464900001446949
0.006451164001191501
0.006058467999537243
0.005964018000668148
Epoch 760: train loss is 0.29494, validate loss is 0.54124
0.035889638998924056
0.025854642000922468
0.013755856998614036
0.010736347001511604
0.009492876000877004
0.009526126999844564
0.009801936001167633
0.009478813997702673
0.009711721999337897
0.00999804900129675
Epoch 770: train loss is 0.29362, validate loss is 0.54119
0.036983997997595
0.025583979000657564
0.009829455997532932
0.008046686998568475
0.007180828000855399
0.006563270002516219
0.006166817001940217
0.0060331919994496275
0.006690219001029618
0.006493860000773566
Epoch 780: train loss is 0.29232, validate loss is 0.54114
0.042043067998747574
0.026245045999530703
0.014528401003190083
0.010224805999314412
0.009361750999232754
0.008697393001057208
0.008725339997909032
0.029628811000293354
0.008995424999739043
0.00861930700193625
Epoch 790: train loss is 0.29103, validate loss is 0.54110
0.046511577998899156
0.009446501000638818
0.008079048999206861
0.006606872000702424
0.0063419260004593525
0.005887631999939913
0.006046180998964701
0.005960222999419784
0.005841141999553656
0.005853585000295425
Epoch 800: train loss is 0.28977, validate loss is 0.54107
0.027822540996567113
0.039790864000678994
0.011246431000472512
0.00923432199851959
0.009176600000500912
0.009484673999395454
0.00911149899911834
0.009035274997586384
0.00954527700014296
0.009187379000650253
Epoch 810: train loss is 0.28852, validate loss is 0.54105
0.03481446399746346
0.012214547998155467
0.009634649999497924
0.008320443997945404
0.010470736000570469
0.008604894999734825
0.008232950000092387
0.008207154998672195
0.008535188000678318
0.008511001000442775
Epoch 820: train loss is 0.28729, validate loss is 0.54103
0.008786835998762399
0.009908972999255639
0.007318971998756751
0.007791173000441631
0.009785411999473581
0.009128069003054406
0.00746118899769499
0.006275686999288155
0.005952681000053417
0.005824956999276765
Epoch 830: train loss is 0.28607, validate loss is 0.54101
0.0361654410007759
0.021101132999319816
0.010384408000390977
0.008084261000476545
0.007585021998238517
0.0062962070005596615
0.006154106002213666
0.005977443997835508
0.006257999000808923
0.006442014997446677
Epoch 840: train loss is 0.28487, validate loss is 0.54101
0.03311670599941863
0.024768283001321834
0.009725935997266788
0.007704943000135245
0.007311884000955615
0.006355067998811137
0.005997823998768581
0.006013646001520101
Training iteration stop at iteration 847
Confusion matrix:
[[0.93 0.   0.02 0.04 0.   0.   0.02 0.   0.   0.  ]
 [0.02 0.95 0.   0.03 0.   0.   0.   0.   0.   0.  ]
 [0.02 0.   0.61 0.04 0.22 0.   0.11 0.   0.   0.  ]
 [0.07 0.05 0.   0.8  0.03 0.   0.05 0.   0.   0.  ]
 [0.   0.   0.09 0.05 0.74 0.   0.12 0.   0.   0.  ]
 [0.   0.   0.   0.   0.   0.92 0.   0.08 0.   0.  ]
 [0.23 0.   0.09 0.02 0.19 0.   0.45 0.   0.02 0.  ]
 [0.   0.   0.   0.   0.   0.06 0.   0.84 0.   0.1 ]
 [0.   0.   0.   0.02 0.02 0.04 0.   0.   0.93 0.  ]
 [0.   0.   0.   0.   0.   0.02 0.   0.   0.   0.98]]
Diagonal values:
[0.93 0.95 0.61 0.8  0.74 0.92 0.45 0.84 0.93 0.98]
